{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../gp_sinkhorn/')\n",
    "sys.path.append('./..')\n",
    "from SDE_solver import solve_sde_RK\n",
    "from gp_sinkhorn.utils import plot_trajectories_2\n",
    "from MLE_drift import *\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mocap = pkl.load(open(\"./../assets/motion_data.pkl\", \"rb\"))\n",
    "#mocap = pkl.load(open(\"./motion_data (4).pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dict, downsampled_dict, key_ = mocap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29', '07', 515, 533]\n",
      "['29', '02', 486, 505]\n"
     ]
    }
   ],
   "source": [
    "key_dict = {}\n",
    "for i in key_:\n",
    "    if i[0] != '29':\n",
    "        key_dict[i[0]+i[1]] = [i[2],i[3]]\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Estimating speed boundaries from position only \n",
    "\n",
    "\n",
    "The next cell shows you how to obtain the speed timeseries and subsequently speed boundaries given only position time series as inputs which is needed for the MOCAP data. Once obtain position and speed boundaries must be concatenated respectively before feeding to IPFP. Virtually this is all the setup we need + the motion priors illustrated in the earlier part of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "def estimate_boundary_velocities(X, window=7, poly=5, mode='nearest'):\n",
    "    n, t, d = X.shape\n",
    "    \n",
    "    V = np.zeros((n,t,d))\n",
    "    \n",
    "    Xnp = np.array(X)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for dj in range(d):\n",
    "            V[i, :, dj] = savgol_filter(Xnp[i, :, dj], window, poly, mode=mode, deriv=1, delta=0.01)\n",
    "    \n",
    "    return torch.tensor(V).double()\n",
    "\n",
    "\n",
    "# Vts = estimate_boundary_velocities(Xts[:,:,:dim*particles], window=3, poly=2, mode=\"interp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key  29 02  has been cut\n",
      "Key  29 07  has been cut\n",
      "Key  30 07  has been cut\n"
     ]
    }
   ],
   "source": [
    "out_mat_pos = []\n",
    "out_mat_vel = []\n",
    "\n",
    "P_0 = []\n",
    "P_1 = []\n",
    "\n",
    "\n",
    "sensor_no = 3\n",
    "\n",
    "for k, v in full_dict.items():\n",
    "    for k1, v1 in v.items():\n",
    "        try:\n",
    "            out_mat_vel.append(\n",
    "                estimate_boundary_velocities(torch.tensor([v1]), window=5, poly=3, mode=\"interp\")[0]\n",
    "            )\n",
    "\n",
    "            out_mat_pos.append(\n",
    "                torch.tensor([v1])[0]\n",
    "            )\n",
    "            start,end = key_dict[k+k1][0],key_dict[k+k1][1]\n",
    "            \n",
    "            \n",
    "            P_0.append(torch.cat((out_mat_pos[-1][start][:sensor_no], out_mat_vel[-1][start][:sensor_no])))\n",
    "\n",
    "            P_1.append(torch.cat((out_mat_pos[-1][end][:sensor_no], out_mat_vel[-1][end][:sensor_no])))\n",
    "        except:\n",
    "            print(\"Key \",k,k1,\" has been cut\")\n",
    "\n",
    "\n",
    "# out_mat = torch.tensor(out_mat).double?()\n",
    "# print(P_0)\n",
    "P_0 = torch.vstack(P_0)\n",
    "P_1 = torch.vstack(P_1)\n",
    "\n",
    "P = torch.vstack([P_0,P_1])\n",
    "P_0 = (P_0-P.mean(axis=0))/P.std(axis=0)\n",
    "P_1 = (P_1-P.mean(axis=0))/P.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_sde_RK_s(b_drift=None, sigma=None, X0=None, dt=1.0, N=100, t0=0.0,\n",
    "                 theta=None, noise=False, forwards=True):\n",
    "    \"\"\"\n",
    "            Euler Mayurama method\n",
    "    Syntax:\n",
    "    ----------\n",
    "    solve_sde(b_drift=None, sigma=None, X0=None, dt=None, N=100, t0=0, DW=None)\n",
    "    Parameters:\n",
    "    ----------\n",
    "        b_drift  : Time dependan drift, the X state (with last dimension as time)\n",
    "                defines the differential equation.\n",
    "        sigma  : a  constant volatility\n",
    "        X0    : Initial conditions of the SDE. Mandatory for SDEs\n",
    "                with variables > 1 (default: gaussian np.random)\n",
    "        dt    : The timestep of the solution\n",
    "                (default: 1)\n",
    "        N     : The number of timesteps (defines the length of the timeseries)\n",
    "                (default: 100)\n",
    "        t0    : The initial time of the solution\n",
    "                (default: 0)\n",
    "\n",
    "    \"\"\"\n",
    "    N = int(N) + 1\n",
    "    if b_drift is None or sigma is None:\n",
    "        raise ValueError(\"Error: SDE not defined.\")\n",
    "\n",
    "    n, d, *_ = X0.shape\n",
    "\n",
    "    T = torch.tensor(dt * N)\n",
    "    DWs = torch.empty((n, N - 1, d)).normal_(mean=0, std=1) * math.sqrt(dt)\n",
    "\n",
    "    Y, ti = torch.zeros((n, N, d + 1)).double(), torch.arange(N).double() * dt + t0\n",
    "    t0rep = (\n",
    "        t0 * torch.ones((X0.shape[0], 1)).double() if forwards\n",
    "        else (T - t0) * torch.ones((X0.shape[0], 1)).double()\n",
    "    )\n",
    "    Y = torch.cat((X0, t0rep), axis=1)[:, None, :]\n",
    "    T = dt * N\n",
    "    for n in range(N - 1):\n",
    "        t = ti[n + 1]  # 1)\n",
    "        b, DW_n = b_drift(Y[:, n, :]), DWs[:, n, :]\n",
    "        \n",
    "#         import pdb; pdb.set_trace()\n",
    "        newY = (\n",
    "                Y[:, n, :-1] + b * dt + sigma * DW_n\n",
    "        )\n",
    "\n",
    "        trep = (\n",
    "            t.repeat(newY.shape[0]).reshape(-1, 1) if forwards\n",
    "            else T - t.repeat(newY.shape[0]).reshape(-1, 1)\n",
    "        )\n",
    "        # print(trep)\n",
    "        tocat = torch.cat((newY, trep), dim=1)[:, None, :]\n",
    "        Y = torch.cat((Y, tocat), dim=1)\n",
    "    if torch.isnan(Y).any() or torch.isinf(Y).any(): import pdb; pdb.set_trace()\n",
    "\n",
    "    return ti, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Noisy Spring Based data\n",
    "\n",
    "Here we simmulate some OU data using the EM SDE Solver . We will use this data to fit forwards and backwards drifts.\n",
    "\n",
    "The system we  are implementing here is :\n",
    "\n",
    "\\begin{align}\n",
    "d\\begin{pmatrix}\n",
    "\\mathbf{x} \\\\\n",
    "\\mathbf{v}\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "\\mathbf{v} \\\\\n",
    "\\mathrm{\\mathbf{K}} \\mathbf{x} - \\beta\\mathbf{v} \n",
    "\\end{pmatrix}dt + \\gamma\\begin{pmatrix}\n",
    "0\\\\\n",
    "1\n",
    "\\end{pmatrix}dW_t\n",
    "\\end{align}\n",
    "\n",
    "Where we try the following settings for  $\\mathrm{\\mathbf{K}}$ :\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{\\mathbf{K}} = \\begin{pmatrix}\n",
    "-1 & -0.5 \\\\\n",
    "-0.5 & -1\n",
    "\\end{pmatrix}, \\quad \\mathrm{\\mathbf{K}} = \\begin{pmatrix}\n",
    "-1 & 0 \\\\\n",
    "0 & -1\n",
    "\\end{pmatrix}, \\quad \\mathrm{\\mathbf{K}} = \\begin{pmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "This is only a 2x2 example however for block structure (many particles) we can imppose a block diag structure for example (correlates within a particles dimensions but not across particles).  The last setting where the spring matrix is 0 corresponds to a free particle experiencing no forces all we get out of this are some sound regularity constraints for motion that vanilla Brownian dynamics fails to impose whilst Langevin dynamics succesfully imposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prior_langevin_diffusion_coeficient(dim_times_particles=1, gamma=1):\n",
    "    \"\"\"\n",
    "    Creates the diffussion across all dimensions and across al particles\n",
    "    for a classical motion prior\n",
    "    \"\"\"\n",
    "    zs = torch.zeros((dim_times_particles,1))\n",
    "    ons = torch.ones((dim_times_particles,1))\n",
    "    \n",
    "    return gamma * torch.cat((zs, ons), axis=0).T\n",
    "\n",
    "\n",
    "def create_dimension_correlation_matrix(dim=1, decoupled=True):\n",
    "    \"\"\"\n",
    "    Creates the coupling matrix within the dimensions of a single particle\n",
    "    \"\"\"\n",
    "    corr = torch.tensor(torch.eye(dim))\n",
    "    if not decoupled:\n",
    "        rows, col = torch.range(0,dim-1).long(), torch.range(0,dim-1).long()\n",
    "        halfs = 0.5 * torch.ones((dim, dim))\n",
    "        halfs[rows, col] = 0.0\n",
    "        return corr + halfs\n",
    "    return corr\n",
    "\n",
    "\n",
    "def create_full_correlation_matrix(\n",
    "    dim_no=1, particle_no=1, decoupled_dim=True, decoupled_particles=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Ultimately this just creates a large matrix with 1s in the diagonal\n",
    "    and 0.5's everywhere else however it can be more flexible and\n",
    "    allow for block structure\n",
    "    \n",
    "    dim_no : number of dimensions of each particle / sensors\n",
    "    particle_no: number of particles / sensors\n",
    "    \"\"\"\n",
    "    \n",
    "    # create the diagonal blocks\n",
    "    dim_mat = create_dimension_correlation_matrix(dim_no, decoupled_dim)\n",
    "    \n",
    "    full_dim = dim_no * particle_no\n",
    "    big_corr = (torch.zeros((full_dim, full_dim)) if \n",
    "                decoupled_particles else 0.5 * torch.ones((full_dim, full_dim)) )\n",
    "    \n",
    "    # set block diagonals    \n",
    "    for i in range(particle_no):\n",
    "        big_corr[i * dim: (i+1) * dim, i * dim: (i+1) * dim] = torch.tensor(dim_mat)\n",
    "    \n",
    "    return big_corr\n",
    "\n",
    "\n",
    "def create_prior_langevin_drift(\n",
    "    dim_no=1, particle_no=1,\n",
    "    free_particle=True, beta=1.0,\n",
    "    decoupled_dim=True, decoupled_particles=True,\n",
    "    hooks_constant = 0.01\n",
    "):\n",
    "    \"\"\"\n",
    "    This creates the linear drift coeficient for motion\n",
    "    Set beta to 0 for undappened motion\n",
    "    \"\"\"\n",
    "    full_dim = dim_no * particle_no\n",
    "    # correlation / spring constant matrix with unit mass \n",
    "    K = (create_full_correlation_matrix(dim_no, particle_no, decoupled_dim, decoupled_particles)\n",
    "        if not free_particle else torch.zeros((dim_no, particle_no))).double()\n",
    "    \n",
    "    K *= hooks_constant\n",
    "    def linear_drift(phase_space_coords):\n",
    "        x = phase_space_coords[:, :full_dim]\n",
    "        v = phase_space_coords[:, full_dim:-1]\n",
    "\n",
    "        xn = v\n",
    "        vn = x.mm(K.T) - beta * v\n",
    "\n",
    "        return torch.cat((xn, vn), axis=1)\n",
    "    \n",
    "    return linear_drift\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 15\n",
    "\n",
    "# mu, std = torch.tensor([[np.pi/4.0] * particles, [np.pi/4.0]*particles ]), (0.1 * torch.eye(dim*particles) )\n",
    "# X_0 = torch.distributions.MultivariateNormal(mu.double().flatten(), std.double()).sample((num_samples,)) #.reshape(num_samples, dim,-1)\n",
    "# V_0 = torch.distributions.MultivariateNormal(mu.double().flatten(), std.double()).sample((num_samples,))\n",
    "\n",
    "# P_0 = torch.cat((X_0, V_0), axis=1)\n",
    "# print(P_0.shape)\n",
    "#P_0 = (P_0 - P_0.mean(axis=0)) / P_0.std(axis=0)\n",
    "#P_1 = (P_1 - P_1.mean(axis=0)) / P_1.std(axis=0)\n",
    "P_0_time_aug = torch.cat((P_0, torch.zeros(P_0.shape[0],1)), axis=1)\n",
    "# print(P_0_time_aug.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " <ipython-input-8-db09ef1f8ddd>:16: UserWarning:To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " <ipython-input-8-db09ef1f8ddd>:18: UserWarning:torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      " <ipython-input-8-db09ef1f8ddd>:46: UserWarning:To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 6]), torch.Size([1, 6]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 3\n",
    "particles = 1\n",
    "gamma = 3\n",
    "sigma_t = create_prior_langevin_diffusion_coeficient(dim * particles, gamma=gamma) \n",
    "beta  = 3 # Damping\n",
    "free_particle = False\n",
    "# this constant directly affects the sinusoids period\n",
    "k = -14\n",
    "\n",
    "# dt = 0.05\n",
    "N = 100\n",
    "dt = 1.0 / N\n",
    "b_drift = create_prior_langevin_drift(\n",
    "    dim_no=dim,\n",
    "    particle_no=particles,\n",
    "    beta=beta,\n",
    "    free_particle=free_particle,\n",
    "    hooks_constant=k,\n",
    "    decoupled_dim=False, decoupled_particles=True\n",
    ")\n",
    "\n",
    "# Shape debug\n",
    "b_drift(P_0_time_aug).shape, sigma_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3000, 0.3000, 0.3000, 3.0000, 3.0000, 3.0000]])\n",
      "torch.Size([6, 6])\n",
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " <ipython-input-11-cbad774fd8d1>:1: UserWarning:To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " c:\\users\\vargf\\onedrive\\documents\\projects\\gp_sinkhorn\\gp_sinkhorn\\GP.py:111: UserWarning:To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "sigma_tt = torch.tensor(sigma_t)\n",
    "sigma_tt[sigma_tt==0] = 0.3\n",
    "\n",
    "print(sigma_tt)\n",
    "prior_X_0=torch.cat((P_1,P_0))\n",
    "\n",
    "\n",
    "num_samples_prior = 100\n",
    "mu, std = P_0.mean(axis=0), torch.diag(P_0.std(axis=0))\n",
    "print(std.shape)\n",
    "prior_X_0_1 = torch.distributions.MultivariateNormal(mu.double().flatten(), std.double()).sample((num_samples_prior,))\n",
    "\n",
    "mu2, std2 = P_1.mean(axis=0), torch.diag(P_1.std(axis=0))\n",
    "print(std2.shape)\n",
    "prior_X_0_2 = torch.distributions.MultivariateNormal(mu2.double().flatten(), std2.double()).sample((num_samples_prior,))\n",
    "\n",
    "\n",
    "prior_X_0f = torch.cat((prior_X_0_1,prior_X_0_2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = MLE_IPFP(\n",
    "    P_0,P_1,\n",
    "     N=N,prior_X_0=prior_X_0f,\n",
    "    prior_drift=b_drift, iteration=10, sigma=(sigma_tt.flatten()),gp_mean_prior_flag=True, plot=True, langevin=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
